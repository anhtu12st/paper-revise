# Story 2.1: RBS-QA Belief State Tracker Infrastructure

## Status
ðŸš§ **Approved**

## Acceptance Criteria
- [ ] Implement `BeliefStateTracker` component with non-monotonic reasoning
- [ ] Support belief state updates across segments using GMM context
- [ ] Re-scoring mechanism for previously found spans with new context
- [ ] Confidence calibration and tracking across segments
- [ ] Backward compatibility with existing GMM-XLNet models

## Description

This story implements the core **Dynamic Belief-State Module** for RBS-QA, which tracks the best answer span found across all processed segments and enables non-monotonic reasoning by revising previous beliefs when new context becomes available.

## Implementation Details

### 1. BeliefState Data Structure

```python
@dataclass
class BeliefState:
    best_span: Optional[Tuple[int, int]]     # Global (start, end) token indices
    confidence: float                         # Calibrated confidence score [0.0, 1.0]
    segment_id: int                           # Segment where best span was found
    span_history: List[SpanCandidate]         # All candidate spans considered
    confidence_history: List[float]           # Confidence trend analysis
    revision_count: int                       # Number of non-monotonic revisions
    total_segments: int                       # Total segments processed

@dataclass
class SpanCandidate:
    span: Tuple[int, int]                     # (start, end) global token indices
    confidence: float                         # Confidence score
    segment_id: int                           # Origin segment
    gmm_context_hash: int                     # GMM state when span was found
```

### 2. BeliefStateTracker Component

**File Location**: `src/rbsqa/belief_state.py`

```python
class BeliefStateTracker(nn.Module):
    def __init__(self,
                 max_segments: int = 32,
                 confidence_threshold: float = 0.7,
                 re_scoring_method: str = "context_weighted",
                 enable_trend_analysis: bool = True):
        super().__init__()
        self.max_segments = max_segments
        self.confidence_threshold = confidence_threshold
        self.re_scoring_method = re_scoring_method
        self.enable_trend_analysis = enable_trend_analysis

        # Learnable parameters for confidence calibration
        self.confidence_scaler = nn.Parameter(torch.ones(1))
        self.confidence_bias = nn.Parameter(torch.zeros(1))

        # Optional: Learnable re-scoring network
        if re_scoring_method == "learned":
            self.re_score_network = nn.Sequential(
                nn.Linear(768, 256),  # GMM context dim + span features
                nn.ReLU(),
                nn.Linear(256, 1),
                nn.Sigmoid()
            )

    def update_belief(self,
                     current_logits: Tuple[torch.Tensor, torch.Tensor],
                     current_segment_id: int,
                     gmm_context: torch.Tensor,
                     global_offset: int) -> BeliefState:
        """
        Update belief state with new segment information.

        Args:
            current_logits: (start_logits, end_logits) for current segment
            current_segment_id: Index of current segment (0-based)
            gmm_context: Aggregated GMM memory context [batch, seq_len, hidden_dim]
            global_offset: Token offset for global index mapping

        Returns:
            Updated BeliefState with potential non-monotonic revisions
        """

    def re_score_past_spans(self,
                           past_spans: List[SpanCandidate],
                           gmm_context: torch.Tensor) -> List[SpanCandidate]:
        """
        Re-score previously found spans using new GMM context.
        This enables non-monotonic reasoning.
        """

    def extract_best_span(self,
                         logits: Tuple[torch.Tensor, torch.Tensor],
                         segment_id: int,
                         global_offset: int) -> SpanCandidate:
        """Extract best span from current segment logits."""

    def compute_confidence(self,
                          start_logits: torch.Tensor,
                          end_logits: torch.Tensor,
                          start_idx: int,
                          end_idx: int) -> float:
        """Compute calibrated confidence for a span."""

    def should_halt(self) -> bool:
        """Determine if current belief warrants halting."""
        return self.belief.confidence >= self.confidence_threshold

    def reset_belief(self) -> None:
        """Reset belief state for new document."""
        self.belief = BeliefState(
            best_span=None,
            confidence=0.0,
            segment_id=-1,
            span_history=[],
            confidence_history=[],
            revision_count=0,
            total_segments=0
        )
```

### 3. Integration Points

**With GMMXLNetForQA**:
- Hook into forward pass after QA head logits generation
- Use GMM aggregated memory context for re-scoring
- Preserve existing memory state propagation

**Data Processing**:
- Extend time-step-major batching with belief state propagation
- Add belief state serialization for checkpoints

### 4. Non-Monotonic Reasoning Algorithm

```python
def non_monotonic_update(self, current_segment, gmm_context):
    # 1. Extract best span from current segment
    current_best = self.extract_best_span(current_segment)

    # 2. If we have a previous belief, re-score it with new context
    if self.belief.best_span is not None:
        revised_confidence = self.re_score_with_context(
            self.belief.best_span, gmm_context
        )

        # 3. Non-monotonic decision: new span vs revised old span
        if revised_confidence > current_best.confidence:
            # Old belief confirmed/boosted by new context
            self.belief.confidence = revised_confidence
            self.belief.span_history.append(current_best)
        else:
            # New span beats revised old span (belief revision)
            self.belief.best_span = current_best.span
            self.belief.confidence = current_best.confidence
            self.belief.segment_id = current_best.segment_id
            self.belief.revision_count += 1
    else:
        # First segment: initialize belief
        self.belief.best_span = current_best.span
        self.belief.confidence = current_best.confidence
        self.belief.segment_id = current_best.segment_id
```

### 5. Testing Strategy

**Unit Tests**:
- `test_belief_state_initialization`
- `test_span_extraction_accuracy`
- `test_confidence_calibration`
- `test_non_monotonic_revision`
- `test_re_scoring_with_new_context`

**Integration Tests**:
- `test_gmm_context_integration`
- `test_backward_compatibility_with_gmm`
- `test_checkpoint_serialization`

**Performance Tests**:
- Memory usage across segments
- Computation overhead vs baseline GMM
- Non-monotonic revision accuracy

### 6. Backward Compatibility

**Existing Code Preservation**:
- All existing GMM-XLNet functionality remains unchanged
- Belief state tracking is optional (enabled via config)
- Standard GMM models continue to work without modification

**Configuration Integration**:
```python
# Extend existing GMMTrainingConfig
class RBSTrainingConfig(GMMTrainingConfig):
    use_belief_state: bool = True
    belief_state_threshold: float = 0.7
    enable_re_scoring: bool = True
    confidence_calibration: bool = True
```

### 7. Success Metrics

**Accuracy Improvements**:
- Non-monotonic revision detection rate > 80%
- Confidence calibration error < 0.1
- End-to-end QA F1 improvement over GMM baseline

**Efficiency Metrics**:
- Belief tracking overhead < 5% compute time
- Memory overhead < 10MB per document
- Re-scoring latency < 10ms per segment

### 8. Dependencies

**Required**:
- Existing GMM-XLNet components
- PyTorch >= 2.8.0
- Existing training infrastructure

**Optional**:
- Confidence calibration datasets
- Re-scoring network pretraining

### 9. Technical Notes

**Memory Management**:
- Belief state is lightweight (< 1KB per document)
- Span history truncated to prevent memory bloat
- Efficient tensor operations for re-scoring

**Numerical Stability**:
- Confidence bounds in [0, 1] with sigmoid
- Gradient clipping for re-scoring network
- Temperature scaling for calibration

**Error Handling**:
- Graceful degradation if re-scoring fails
- Fallback to original belief if revision invalid
- Comprehensive logging for debugging

## Definition of Done

- [ ] All unit tests pass (95%+ coverage)
- [ ] Integration tests with GMM-XLNet pass
- [ ] Backward compatibility verified with existing models
- [ ] Performance benchmarks meet success criteria
- [ ] Documentation updated with belief state usage
- [ ] Code review completed and approved
- [ ] Example notebook demonstrating non-monotonic reasoning

## Out of Scope

- Halting policy network (separate story)
- RL training pipeline (separate story)
- Advanced confidence calibration methods
- Multi-document belief tracking
- Interactive belief visualization

## Notes

This component forms the foundation for RBS-QA's non-monotonic reasoning capabilities. It must work seamlessly with the existing GMM-XLNet architecture while adding the ability to revise previously held beliefs when new context becomes available.

The design prioritizes:
1. **Correctness**: Accurate belief tracking and revision
2. **Efficiency**: Minimal computational overhead
3. **Compatibility**: Seamless integration with existing code
4. **Debuggability**: Comprehensive logging and visualization