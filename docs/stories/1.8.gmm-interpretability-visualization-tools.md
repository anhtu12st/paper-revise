# Story 1.8: GMM Interpretability and Visualization Tools

## Status

Draft

## Story

**As a** research engineer,
**I want** to implement analysis tools that reveal expert specialization patterns,
**so that** researchers can understand what types of information each expert learns to store.

## Acceptance Criteria

1. **GMMAnalyzer class created** in `src/gmmxlnet/utils/gmm_analysis.py`
2. **Routing probability tracking** across document segments with export to JSON
3. **Expert activation frequency analysis** identifying which experts activate for which inputs
4. **Memory specialization metrics**: entropy, diversity, expert utilization balance
5. **Visualization functions**: routing heatmaps, expert activation timelines, specialization dendrograms
6. **Example analysis script** demonstrating interpretability workflow on sample documents

## Integration Verification

**IV1**: Existing `MemoryVisualizer` continues to work for non-GMM models
**IV2**: Visualization functions produce valid matplotlib figures without errors
**IV3**: Analysis tools work with time-step-major batched evaluation pipeline

## Tasks / Subtasks

- [ ] Create GMMAnalyzer class (AC: 1)
  - [ ] Create `src/gmmxlnet/utils/__init__.py`
  - [ ] Create `src/gmmxlnet/utils/gmm_analysis.py`
  - [ ] Define GMMAnalyzer class
  - [ ] Add initialization with model and evaluation data
- [ ] Implement routing probability tracking (AC: 2)
  - [ ] Implement `track_routing(model, eval_dataloader)` method
  - [ ] Collect routing_probs across all segments
  - [ ] Store segment-level routing: {segment_id: routing_probs}
  - [ ] Implement `export_routing_to_json(output_path)` method
  - [ ] Add metadata: document_id, segment_position, routing_probs
- [ ] Implement expert activation analysis (AC: 3)
  - [ ] Implement `compute_expert_activations()` method
  - [ ] Calculate per-expert activation frequency across dataset
  - [ ] Identify which experts activate for which content types
  - [ ] Group activations by document type, question type, etc.
  - [ ] Export activation statistics to JSON
- [ ] Implement specialization metrics (AC: 4)
  - [ ] Implement `compute_routing_entropy()` - measure routing diversity
  - [ ] Implement `compute_expert_diversity()` - measure expert differentiation
  - [ ] Implement `compute_utilization_balance()` - measure load balancing
  - [ ] Implement `compute_specialization_score()` - composite metric
  - [ ] Add statistical significance testing for specialization
- [ ] Create visualization functions (AC: 5)
  - [ ] Implement `plot_routing_heatmap(routing_data)` - segment × expert heatmap
  - [ ] Implement `plot_expert_activation_timeline(routing_data)` - time series per expert
  - [ ] Implement `plot_specialization_dendrogram(expert_embeddings)` - hierarchical clustering
  - [ ] Implement `plot_expert_utilization_bar(activation_freq)` - bar chart
  - [ ] Implement `plot_routing_entropy_distribution()` - histogram
  - [ ] Save all plots to file with configurable format (PNG, PDF, SVG)
- [ ] Create example analysis script (AC: 6)
  - [ ] Create `examples/analyze_gmm_experts.py`
  - [ ] Load trained GMM model
  - [ ] Run evaluation and track routing
  - [ ] Compute all specialization metrics
  - [ ] Generate all visualizations
  - [ ] Save analysis report (JSON + figures)
  - [ ] Add command-line arguments for model path, data path, output dir
- [ ] Add helper utilities
  - [ ] Implement `extract_expert_embeddings(model)` - get expert memory representations
  - [ ] Implement `cluster_experts(embeddings, method)` - k-means or hierarchical
  - [ ] Implement `compute_expert_similarity(expert_i, expert_j)` - cosine similarity
- [ ] Create unit tests
  - [ ] Create `tests/unit/test_gmm_analysis.py`
  - [ ] Test routing tracking with dummy data
  - [ ] Test metric calculations
  - [ ] Test visualization functions produce valid figures
  - [ ] Test JSON export format
  - [ ] Verify >= 70% coverage for gmm_analysis.py
- [ ] Run integration verification (IV1-IV3)
  - [ ] Verify existing MemoryVisualizer still works
  - [ ] Test visualizations render without errors
  - [ ] Test with time-step-major evaluation

## Dev Notes

### Component Architecture

**GMMAnalyzer Responsibility:**
- Track routing probabilities across evaluation
- Compute expert specialization metrics
- Generate visualizations for interpretability analysis
- Export analysis results for publication

**Key Interfaces:**
- `track_routing(model, dataloader)` - Collect routing during evaluation
- `compute_expert_activations()` - Analyze activation patterns
- `compute_specialization_metrics()` - Calculate metrics
- `generate_visualizations(output_dir)` - Create all plots
- `export_analysis_report(output_path)` - Save JSON report

**Analysis Outputs:**
- Routing heatmaps (segment × expert)
- Activation timelines (expert activation over time)
- Specialization dendrograms (hierarchical expert clustering)
- Utilization bar charts (load balancing visualization)
- JSON analysis report with all metrics

### Source Tree

**File Location:**
```
src/gmmxlnet/utils/
├── __init__.py                    # Export GMMAnalyzer
├── gmm_analysis.py                # ✨ NEW - This story
└── routing_visualization.py       # ✨ NEW - Visualization helpers
```

**Example Script:**
```
examples/
└── analyze_gmm_experts.py         # ✨ NEW - Analysis workflow
```

**Test File:**
```
tests/unit/
└── test_gmm_analysis.py           # ✨ NEW - Analysis tests
```

### Coding Standards

**Visualization Standards:**
- Use matplotlib for all plots
- Consistent color scheme across visualizations
- Clear axis labels and titles
- Save figures in publication-quality resolution (300 DPI)
- Support both PNG and PDF export

**Data Export Format (JSON):**
```json
{
    "model_id": "username/gmmxlnet-squad-k4",
    "num_experts": 4,
    "evaluation_dataset": "squad_v2_dev",
    "metrics": {
        "routing_entropy": 1.23,
        "expert_diversity": 0.87,
        "utilization_balance": 0.92,
        "specialization_score": 0.78
    },
    "expert_activations": {
        "expert_0": 0.28,
        "expert_1": 0.24,
        "expert_2": 0.26,
        "expert_3": 0.22
    },
    "routing_data": [
        {
            "document_id": "doc_001",
            "segment_idx": 0,
            "routing_probs": [0.3, 0.2, 0.4, 0.1]
        },
        ...
    ]
}
```

### Key Implementation Notes

**Routing Entropy:**
```python
def compute_routing_entropy(routing_probs):
    """
    Compute entropy of routing distribution.
    High entropy → uniform routing (less specialization)
    Low entropy → peaked routing (more specialization)

    Args:
        routing_probs: (num_segments, num_experts)

    Returns:
        mean_entropy: float
    """
    entropy = -torch.sum(routing_probs * torch.log(routing_probs + 1e-10), dim=-1)
    return entropy.mean().item()
```

**Expert Diversity:**
```python
def compute_expert_diversity(expert_embeddings):
    """
    Measure how different experts are from each other.
    Use average pairwise cosine distance.

    Higher diversity → more specialization
    """
    similarities = cosine_similarity_matrix(expert_embeddings)
    # Average off-diagonal elements
    diversity = 1 - similarities[~torch.eye(k, dtype=bool)].mean()
    return diversity.item()
```

**Utilization Balance:**
```python
def compute_utilization_balance(activation_freq):
    """
    Measure how evenly experts are used.
    Coefficient of variation of activation frequencies.

    Perfect balance = 0 (all experts equally used)
    """
    std = activation_freq.std()
    mean = activation_freq.mean()
    cv = std / (mean + 1e-10)
    balance = 1 / (1 + cv)  # Normalize to [0, 1]
    return balance
```

### Visualization Examples

**Routing Heatmap:**
- X-axis: Experts (0 to k-1)
- Y-axis: Segments (0 to num_segments)
- Color: Routing probability (0 to 1)
- Colormap: viridis or plasma

**Activation Timeline:**
- X-axis: Segment index
- Y-axis: Routing probability
- Lines: One line per expert (different colors)
- Shows temporal activation patterns

**Specialization Dendrogram:**
- Hierarchical clustering of expert embeddings
- Shows which experts are similar vs different
- Useful for identifying expert groups

### Testing

**Test File Location:**
- Create `tests/unit/test_gmm_analysis.py`

**Testing Standards:**
- Framework: pytest 7.4.0+
- Coverage Target: >= 70% (visualization code harder to test)

**Test Requirements:**
- Test routing tracking collects data correctly
- Test metric calculations with known inputs:
  - Entropy: uniform distribution → max entropy
  - Diversity: orthogonal experts → max diversity
  - Balance: equal activations → perfect balance
- Test visualization functions return valid Figure objects
- Test JSON export produces valid JSON
- Test example script runs without errors

**Mock Data for Testing:**
```python
def create_mock_routing_data(num_segments=10, num_experts=4):
    return {
        "routing_probs": torch.randn(num_segments, num_experts).softmax(dim=-1),
        "segment_ids": list(range(num_segments)),
        "document_ids": ["doc_0"] * num_segments
    }
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-02 | 1.0 | Initial story created from PRD | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
