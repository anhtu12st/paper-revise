# Story 1.5: Integrate GMM with MemXLNetForQA

## Status

Draft

## Story

**As a** research engineer,
**I want** to create GMMXLNetForQA that orchestrates all GMM components in a unified forward pass,
**so that** users can enable GMM through configuration flags without code changes.

## Acceptance Criteria

1. **GMMXLNetForQA class created** in `src/gmmxlnet/models/gmm_xlnet_qa.py`
2. **Configuration integration** with flags: `use_gmm_memory`, `num_memory_experts`, `gmm_routing_mode`
3. **Forward pass orchestration** integrating all GMM components (GatedMemoryMixture, MemoryGatingNetwork, ExpertUpdater, AggregatedMemoryReader)
4. **Memory state initialization** extended to initialize expert banks when GMM enabled
5. **Output compatibility** ensuring GMM outputs match expected format (start_logits, end_logits, new_memory_state)
6. **Integration test** demonstrating full forward pass with GMM enabled on toy data

## Integration Verification

**IV1**: Models with `use_gmm_memory=False` produce identical outputs to existing models
**IV2**: All existing training scripts work without modification when GMM disabled
**IV3**: Model loading with `from_pretrained()` correctly detects memory type from config

## Tasks / Subtasks

- [ ] Create GMMXLNetForQA class (AC: 1)
  - [ ] Create `src/gmmxlnet/models/gmm_xlnet_qa.py`
  - [ ] Import all GMM components (GatedMemoryMixture, MemoryGatingNetwork, ExpertUpdater, AggregatedMemoryReader)
  - [ ] Import base XLNet model from transformers
  - [ ] Define class inheriting from `nn.Module`
- [ ] Implement configuration and initialization (AC: 2, 4)
  - [ ] Define `__init__(base_model, num_experts, routing_mode, ...)` constructor
  - [ ] Add configuration parameters: use_gmm_memory, num_memory_experts, gmm_routing_mode, routing_temperature
  - [ ] Initialize XLNet base model
  - [ ] Initialize GatedMemoryMixture with expert count
  - [ ] Initialize MemoryGatingNetwork with routing config
  - [ ] Initialize ExpertUpdater with expert-specific gates
  - [ ] Initialize AggregatedMemoryReader with routing mode
  - [ ] Initialize QA head (start/end logits projection)
- [ ] Implement forward pass (AC: 3, 5)
  - [ ] Define `forward(input_ids, attention_mask, memory_state, ...)` method
  - [ ] Pass input through XLNet base model
  - [ ] Extract [MEM_WRITE] token representations
  - [ ] Compute routing probabilities via MemoryGatingNetwork
  - [ ] Update expert memories via ExpertUpdater
  - [ ] Extract [MEM_READ] token positions
  - [ ] Compute aggregated memory via AggregatedMemoryReader
  - [ ] Replace [MEM_READ] embeddings with aggregated memory
  - [ ] Pass through QA head for start/end logits
  - [ ] Return (start_logits, end_logits, new_memory_state, routing_info)
- [ ] Add state management methods
  - [ ] Implement `get_memory_state()` → Dict[str, Tensor] for all k experts
  - [ ] Implement `set_memory_state(memory_state)` for state propagation
  - [ ] Implement `reset_memory()` for new document initialization
- [ ] Add model loading methods
  - [ ] Implement `from_pretrained(model_id)` class method
  - [ ] Add memory type detection from config.json
  - [ ] Handle backward compatibility with non-GMM checkpoints
- [ ] Add routing info accessor (AC: 5)
  - [ ] Return optional routing_info dict: {routing_probs, routing_entropy, expert_activations}
  - [ ] Make routing info optional via return_routing_info flag
- [ ] Create integration test (AC: 6)
  - [ ] Create `tests/integration/test_gmm_integration.py`
  - [ ] Create toy dataset (10 examples, short context)
  - [ ] Initialize GMMXLNetForQA with k=4 experts
  - [ ] Run forward pass and verify outputs
  - [ ] Verify output shapes match expected dimensions
  - [ ] Verify memory state propagation across segments
  - [ ] Test with various configurations (k=2, 4, 8)
- [ ] Run integration verification (IV1-IV3)
  - [ ] Create test comparing GMM-disabled vs baseline model
  - [ ] Verify existing training scripts work
  - [ ] Test from_pretrained() with various checkpoint types

## Dev Notes

### Component Architecture

**GMMXLNetForQA Responsibility:**
- Main model class orchestrating all GMM components in unified forward pass
- Reuses existing XLNet base model, memory token identification, QA head
- Integrates new GMM components for expert memory management

**Key Interfaces:**
- `__init__(base_model, num_experts, ...)` - Initialize GMM-XLNet
- `forward(input_ids, memory_state, ...)` → (start_logits, end_logits, new_memory, routing_info)
- `from_pretrained(model_id)` - Load from HuggingFace Hub
- `save_pretrained(save_path)` - Save checkpoint with GMM state
- `get_memory_state()` → Dict - Access all k expert states

**Component Integration:**
- **Reuses:** XLNet base, memory token identification, QA head, checkpoint patterns
- **Integrates:** GatedMemoryMixture, MemoryGatingNetwork, ExpertUpdater, AggregatedMemoryReader

**Forward Pass Flow:**
```
input_ids, attention_mask
    ↓
XLNet Base Model
    ↓ hidden_states
Extract [MEM_WRITE] tokens
    ↓ write_hiddens
MemoryGatingNetwork → routing_probs
    ↓
ExpertUpdater(expert_states, write_hiddens, routing_probs)
    ↓ updated_expert_states
Extract [MEM_READ] positions
    ↓
AggregatedMemoryReader(expert_states, routing_probs)
    ↓ aggregated_memory
Replace [MEM_READ] embeddings
    ↓ modified_sequence
QA Head (start/end logits)
    ↓
return (start_logits, end_logits, new_memory_state, routing_info)
```

### Source Tree

**File Location:**
```
src/gmmxlnet/
├── __init__.py                    # Export GMMXLNetForQA
└── models/
    ├── __init__.py                # Export all model components
    ├── memory_mixture.py          # Story 1.1
    ├── gating_network.py          # Story 1.2
    ├── expert_updates.py          # Story 1.3
    ├── memory_read.py             # Story 1.4
    └── gmm_xlnet_qa.py            # ✨ NEW - This story
```

### Coding Standards

**Import Pattern:**
```python
# Reuse existing components
from memxlnet.data import ChunkedSquadDataset
from transformers import XLNetModel

# Import GMM components
from .memory_mixture import GatedMemoryMixture
from .gating_network import MemoryGatingNetwork
from .expert_updates import ExpertUpdater
from .memory_read import AggregatedMemoryReader
```

**Configuration Validation:**
- Validate num_experts in [2, 8]
- Validate routing_mode in ["write-based", "read-based"]
- Validate routing_temperature > 0
- Fail fast with clear error messages

### Key Implementation Notes

**Memory State Format:**
```python
{
    "expert_0": Tensor (batch, memory_slots, hidden_dim),
    "expert_1": Tensor (batch, memory_slots, hidden_dim),
    ...
    "expert_k-1": Tensor (batch, memory_slots, hidden_dim),
    "routing_probs": Tensor (batch, k),  # optional, for analysis
}
```

**Routing Info Format:**
```python
{
    "routing_probs": Tensor (batch, k),
    "routing_entropy": Tensor (batch,),
    "expert_activations": Tensor (k,),  # sum of routing probs per expert
}
```

**Backward Compatibility:**
- Check config.json for "memory_type" field
- If missing or "standard", use non-GMM behavior
- If "gmm", load GMM-specific parameters
- Raise clear error if mismatch detected

### Testing

**Test File Location:**
- Create `tests/integration/test_gmm_integration.py`

**Test Requirements:**
- Test full forward pass with toy data
- Test output shapes: start_logits (batch, seq_len), end_logits (batch, seq_len), memory_state (dict)
- Test memory state propagation across 2 segments
- Test routing info returned correctly
- Test various configurations (k=2, 4, 8; different routing modes)
- Test backward compatibility (GMM disabled should match baseline)

**Integration Verification Tests:**
- **IV1:** Compare outputs with use_gmm_memory=False vs baseline
- **IV2:** Import existing training scripts and verify no errors
- **IV3:** Test from_pretrained() with GMM and non-GMM checkpoints

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-02 | 1.0 | Initial story created from PRD | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
