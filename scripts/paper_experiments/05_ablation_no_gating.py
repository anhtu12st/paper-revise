#!/usr/bin/env python3
"""
Ablation Study: Without Gated Memory Updates
=============================================

This script trains with memory tokens but WITHOUT gated updates
to show the importance of the gating mechanism.

Output: outputs/paper_exp_05_ablation_no_gating/
"""

import logging
import sys
from pathlib import Path

import torch

sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from memxlnet.training import TrainingConfig, XLNetRecurrentTrainer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_config():
    """Create configuration without gated memory updates."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    has_cuda = torch.cuda.is_available()

    config = TrainingConfig(
        model_name="xlnet-base-cased",
        max_seq_length=384,
        doc_stride=64,
        dataset_name="squad_v2",
        train_split="train",
        eval_split="validation",
        cache_dir="./.cache",
        max_train_samples=None,
        max_eval_samples=None,
        use_lazy_loading=False,
        progressive_segments=[2, 4, 6],
        max_n_segs=6,
        # Memory WITHOUT gating
        memory_num_tokens=8,
        memory_update="none",  # No gating!
        memory_init="learned",
        memory_impl="token",
        use_global_softmax=True,
        num_epochs=3,
        train_batch_size=16,
        eval_batch_size=32,
        learning_rate=3e-5,
        weight_decay=0.01,
        warmup_ratio=0.1,
        max_grad_norm=1.0,
        gradient_accumulation_steps=1,
        eval_steps=6000,
        save_steps=10000,
        logging_steps=500,
        output_dir="./outputs/paper_exp_05_ablation_no_gating",
        run_name="paper-ablation-no-gating",
        save_total_limit=3,
        no_answer_threshold=1.5,
        use_any_positive_logic=True,
        device=device,
        fp16=has_cuda,
        warmup_freeze_base_epochs=0,
        warmup_disable_global_softmax_epochs=1,
        warmup_disable_any_positive_epochs=0,
        push_to_hub_on_save=False,
    )
    return config


def print_experiment_info(config):
    """Print experiment information."""
    print("\n" + "=" * 80)
    print("üìä PAPER EXPERIMENT 05: ABLATION - NO GATED UPDATES")
    print("=" * 80)
    print()
    print("üéØ OBJECTIVE:")
    print("   Show importance of gated memory update mechanism")
    print()
    print("üìã KEY DIFFERENCE:")
    print(f"   ‚Ä¢ Memory update: {config.memory_update} (vs 'gated')")
    print("   ‚Ä¢ Memory writes without learned gating")
    print()
    print("üíæ OUTPUT:")
    print(f"   ‚Ä¢ Directory: {config.output_dir}")
    print()
    print("=" * 80 + "\n")


def main():
    """Run ablation experiment."""
    print("üöÄ Starting Ablation 05 (No Gating)...\n")
    config = create_config()
    print_experiment_info(config)
    trainer = XLNetRecurrentTrainer(config)

    try:
        trainer.train()
        print("\n‚úÖ Experiment completed!")
        print(f"üìÅ Results: {config.output_dir}")
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted.")
    except Exception as e:
        print(f"\n‚ùå Failed: {e}")
        raise


if __name__ == "__main__":
    main()
