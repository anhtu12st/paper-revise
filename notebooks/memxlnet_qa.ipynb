{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MemXLNet-QA Evaluation Notebook\n",
    "\n",
    "This notebook demonstrates how to load and evaluate the MemXLNet-QA model from checkpoint using the proper data pipeline.\n",
    "\n",
    "**Goal**: Achieve F1 score > 80% on SQuAD v2\n",
    "\n",
    "## Features Demonstrated:\n",
    "- ‚úÖ Model loading with memory state restoration\n",
    "- ‚úÖ Time-step-major batching for proper memory propagation  \n",
    "- ‚úÖ Complete evaluation pipeline using `create_evaluation_dataloader`\n",
    "- ‚úÖ Memory-aware document processing\n",
    "- ‚úÖ SQuAD v2 metrics computation with HasAns/NoAns breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Define all adjustable parameters in one place for reproducibility and easier experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tupa7/private/paper-revise/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import MemXLNet-QA components using proper module paths\n",
    "from src.memxlnet_qa import MemXLNetForQA\n",
    "from src.train import TrainingConfig, XLNetRecurrentTrainer\n",
    "from src.data import create_evaluation_dataloader  # Use proper pipeline!\n",
    "from transformers import XLNetTokenizerFast\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central configuration\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class EvalConfig:\n",
    "    checkpoint_path: str = '../outputs/xlnet-squad-phase2-1/stage_2_segs_2/best_model'\n",
    "    test_size: int = 100\n",
    "    batch_size: int = 8\n",
    "    max_answer_length: int = 30\n",
    "    start_top_k: int = 24\n",
    "    end_top_k: int = 24\n",
    "    no_answer_threshold: float = 1.5  # higher => predict more answers (tune)\n",
    "    use_full_eval: bool = True  # ‚úÖ ENABLED: Run full dataset evaluation\n",
    "\n",
    "EVAL_CFG = EvalConfig()\n",
    "print(EVAL_CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Configuration\n",
    "\n",
    "Load the trained MemXLNet-QA model with memory state restoration and examine the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ../outputs/xlnet-squad-phase2-1/stage_2_segs_2/best_model\n",
      "Loading config from: ../outputs/xlnet-squad-phase2-1/stage_2_segs_2/best_model/training_config.json\n",
      "‚úÖ Checkpoint directory found\n",
      "\n",
      "üìã Training Configuration:\n",
      "  max_seq_length: 384\n",
      "  doc_stride: 64\n",
      "  no_answer_threshold: 1.5\n",
      "  memory_num_tokens: 16\n",
      "  memory_update: gated\n",
      "  memory_init: learned\n",
      "  memory_impl: token\n"
     ]
    }
   ],
   "source": [
    "# Path to the trained checkpoint (adjust if your checkpoint is elsewhere)\n",
    "checkpoint_path = '../outputs/xlnet-squad-phase2-1/stage_2_segs_2/best_model'\n",
    "config_path = os.path.join(checkpoint_path, 'training_config.json')\n",
    "\n",
    "print(f\"Loading model from: {checkpoint_path}\")\n",
    "print(f\"Loading config from: {config_path}\")\n",
    "\n",
    "# Verify checkpoint exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"‚ùå Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Available checkpoints:\")\n",
    "    outputs_dir = '../outputs'\n",
    "    if os.path.exists(outputs_dir):\n",
    "        for item in os.listdir(outputs_dir):\n",
    "            item_path = os.path.join(outputs_dir, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                print(f\"  {item}\")\n",
    "    else:\n",
    "        print(\"  No outputs directory found\")\n",
    "else:\n",
    "    print(\"‚úÖ Checkpoint directory found\")\n",
    "\n",
    "# Load training configuration\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    \n",
    "    print(\"\\nüìã Training Configuration:\")\n",
    "    key_configs = ['max_seq_length', 'doc_stride', 'no_answer_threshold', \n",
    "                   'memory_num_tokens', 'memory_update', 'memory_init', 'memory_impl']\n",
    "    for key in key_configs:\n",
    "        if key in config_data:\n",
    "            print(f\"  {key}: {config_data[key]}\")\n",
    "else:\n",
    "    print(f\"‚ùå Config file not found: {config_path}\")\n",
    "    config_data = {}  # Use defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading MemXLNet-QA model...\n",
      "\n",
      "üéØ Model loaded successfully:\n",
      "  Memory tokens: 16\n",
      "  Memory update: gated\n",
      "  Memory init: learned\n",
      "  Base model: XLNetForQuestionAnsweringSimple\n",
      "  Total parameters: 119,117,570\n",
      "  Memory parameters: 2,373,120 (2.0%)\n",
      "\n",
      "Loading tokenizer...\n",
      "  Vocabulary size: 32032\n",
      "  Original XLNet vocab: ~32000\n",
      "  Added memory tokens: 32\n",
      "  Memory tokens found: 32\n",
      "  Examples: ['<mem_w_6>', '<mem_w_3>', '<mem_w_4>', '<mem_r_10>'] ... ['<mem_w_5>', '<mem_r_6>', '<mem_r_4>', '<mem_r_9>']\n"
     ]
    }
   ],
   "source": [
    "# Load the MemXLNet model with memory state restoration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load model using the fixed from_pretrained method\n",
    "    print(\"Loading MemXLNet-QA model...\")\n",
    "    model = MemXLNetForQA.from_pretrained(checkpoint_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"\\nüéØ Model loaded successfully:\")\n",
    "    print(f\"  Memory tokens: {model.mem_token_count}\")\n",
    "    print(f\"  Memory update: {model.memory_update}\")\n",
    "    print(f\"  Memory init: {model.memory_init}\")\n",
    "    print(f\"  Base model: {type(model.base).__name__}\")\n",
    "    \n",
    "    # Check memory parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    memory_params = 0\n",
    "    if hasattr(model, 'learned_memory'):\n",
    "        memory_params += model.learned_memory.numel()\n",
    "    if hasattr(model, 'memory_gate'):\n",
    "        memory_params += sum(p.numel() for p in model.memory_gate.parameters())\n",
    "    if hasattr(model, 'memory_update_net'):\n",
    "        memory_params += sum(p.numel() for p in model.memory_update_net.parameters())\n",
    "    \n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Memory parameters: {memory_params:,} ({memory_params/total_params*100:.1f}%)\")\n",
    "    \n",
    "    # Load tokenizer with memory tokens\n",
    "    print(\"\\nLoading tokenizer...\")\n",
    "    tokenizer = XLNetTokenizerFast.from_pretrained(checkpoint_path)\n",
    "    print(f\"  Vocabulary size: {len(tokenizer)}\")\n",
    "    print(f\"  Original XLNet vocab: ~32000\")\n",
    "    print(f\"  Added memory tokens: {len(tokenizer) - 32000}\")\n",
    "    \n",
    "    # Check for memory tokens\n",
    "    memory_tokens = [token for token in tokenizer.get_vocab().keys() if 'mem_' in token.lower()]\n",
    "    print(f\"  Memory tokens found: {len(memory_tokens)}\")\n",
    "    if memory_tokens:\n",
    "        print(f\"  Examples: {memory_tokens[:4]} ... {memory_tokens[-4:]}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot load model - checkpoint not found\")\n",
    "    model = None\n",
    "    tokenizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load SQuAD v2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SQuAD v2 validation dataset...\n",
      "Dataset size: 11873 examples\n",
      "\n",
      "Dataset breakdown:\n",
      "  Has answer: 5928 (49.9%)\n",
      "  No answer: 5945 (50.1%)\n",
      "\n",
      "Example:\n",
      "  Question: In what country is Normandy located?...\n",
      "  Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th a...\n",
      "  Answer: ['France', 'France', 'France', 'France']\n",
      "Dataset size: 11873 examples\n",
      "\n",
      "Dataset breakdown:\n",
      "  Has answer: 5928 (49.9%)\n",
      "  No answer: 5945 (50.1%)\n",
      "\n",
      "Example:\n",
      "  Question: In what country is Normandy located?...\n",
      "  Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th a...\n",
      "  Answer: ['France', 'France', 'France', 'France']\n"
     ]
    }
   ],
   "source": [
    "# Load SQuAD v2 validation set\n",
    "print(\"Loading SQuAD v2 validation dataset...\")\n",
    "dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
    "print(f\"Dataset size: {len(dataset)} examples\")\n",
    "\n",
    "# Show dataset statistics\n",
    "has_answer = sum(1 for ex in dataset if len(ex['answers']['text']) > 0)\n",
    "no_answer = len(dataset) - has_answer\n",
    "\n",
    "print(f\"\\nDataset breakdown:\")\n",
    "print(f\"  Has answer: {has_answer} ({has_answer/len(dataset)*100:.1f}%)\")\n",
    "print(f\"  No answer: {no_answer} ({no_answer/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "# Show example\n",
    "example = dataset[0]\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"  Question: {example['question'][:100]}...\")\n",
    "print(f\"  Context: {example['context'][:100]}...\")\n",
    "print(f\"  Answer: {example['answers']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Evaluation Pipeline\n",
    "\n",
    "Use the proper `create_evaluation_dataloader` function for time-step-major batching with memory support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the proper data pipeline functions!\n",
    "from data import create_evaluation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_memory(model, eval_dataloader, eval_dataset, device, no_answer_threshold=None,\n",
    "                           max_answer_length=None, start_top_k=None, end_top_k=None):\n",
    "    \"\"\"\n",
    "    Memory-aware evaluation using time-step-major batches.\n",
    "\n",
    "    Args:\n",
    "        model: MemXLNetForQA\n",
    "        eval_dataloader: iterator yielding list[batch_dict] per document batch (time-step-major)\n",
    "        eval_dataset: SquadLikeQADataset (for optional context)\n",
    "        device: torch.device\n",
    "        no_answer_threshold: float; if (null_score - best_non_null_score) > threshold => predict no answer\n",
    "        max_answer_length: int maximum token span length\n",
    "        start_top_k / end_top_k: prune span search by top-k logits for efficiency\n",
    "    Returns:\n",
    "        List of per-segment prediction dicts with keys:\n",
    "            example_id, example_index, time_step, prediction, best_start, best_end,\n",
    "            best_non_null_score, null_score, confidence\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    if no_answer_threshold is None:\n",
    "        no_answer_threshold = EVAL_CFG.no_answer_threshold\n",
    "    if max_answer_length is None:\n",
    "        max_answer_length = EVAL_CFG.max_answer_length\n",
    "    if start_top_k is None:\n",
    "        start_top_k = EVAL_CFG.start_top_k\n",
    "    if end_top_k is None:\n",
    "        end_top_k = EVAL_CFG.end_top_k\n",
    "\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, time_step_batches in enumerate(tqdm(eval_dataloader, desc=\"Evaluating\")):\n",
    "            memory_bank = {}\n",
    "            for time_step, batch in enumerate(time_step_batches):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch.get('token_type_ids')\n",
    "                if token_type_ids is not None:\n",
    "                    token_type_ids = token_type_ids.to(device)\n",
    "                document_mask = batch['document_mask'].to(device)\n",
    "                example_ids = batch['example_ids']\n",
    "                offset_mapping = batch['offset_mapping']  # list[list[tuple]]\n",
    "                contexts = batch['context']\n",
    "                cls_indices = batch.get('cls_index', [])  # Get CLS indices from batch\n",
    "\n",
    "                # Prepare memory states\n",
    "                memory_states = []\n",
    "                for ex_id, active in zip(example_ids, document_mask.tolist()):\n",
    "                    if not active or ex_id.startswith('padding'):\n",
    "                        memory_states.append(model.get_initial_memory(1, device)[0])\n",
    "                    else:\n",
    "                        prev_memory = memory_bank.get(ex_id)\n",
    "                        if prev_memory is None:\n",
    "                            prev_memory = model.get_initial_memory(1, device)[0]\n",
    "                        memory_states.append(prev_memory)\n",
    "                memory_state_batch = torch.stack(memory_states, dim=0)\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    memory_state=memory_state_batch,\n",
    "                )\n",
    "                start_logits = outputs['start_logits'].cpu().numpy()\n",
    "                end_logits = outputs['end_logits'].cpu().numpy()\n",
    "                new_memory_state = outputs['new_memory_state']\n",
    "\n",
    "                # Update memory\n",
    "                for i, (ex_id, active) in enumerate(zip(example_ids, document_mask.tolist())):\n",
    "                    if active and not ex_id.startswith('padding'):\n",
    "                        memory_bank[ex_id] = new_memory_state[i].detach()\n",
    "\n",
    "                active_mask = document_mask.bool()\n",
    "                if not active_mask.any():\n",
    "                    continue\n",
    "\n",
    "                active_indices = torch.where(active_mask)[0].tolist()\n",
    "                for tensor_idx in active_indices:\n",
    "                    i = tensor_idx\n",
    "                    ex_id = example_ids[i]\n",
    "                    if ex_id.startswith('padding'):\n",
    "                        continue\n",
    "                    # Parse example index from doc_X id\n",
    "                    try:\n",
    "                        example_index = int(ex_id.split('_')[1])\n",
    "                    except Exception:\n",
    "                        example_index = -1\n",
    "\n",
    "                    s_logits = start_logits[i]\n",
    "                    e_logits = end_logits[i]\n",
    "\n",
    "                    # Get CLS index for this example (CRITICAL FIX!)\n",
    "                    cls_idx = 0  # Fallback to position 0\n",
    "                    if i < len(cls_indices):\n",
    "                        cls_idx = int(cls_indices[i]) if isinstance(cls_indices[i], torch.Tensor) else cls_indices[i]\n",
    "                    elif hasattr(input_ids, 'tolist'):\n",
    "                        # Try to find CLS token in input_ids\n",
    "                        input_ids_list = input_ids[i].tolist()\n",
    "                        try:\n",
    "                            cls_idx = input_ids_list.index(tokenizer.cls_token_id) if hasattr(tokenizer, 'cls_token_id') else 0\n",
    "                        except ValueError:\n",
    "                            cls_idx = 0\n",
    "\n",
    "                    # Determine context mask\n",
    "                    if token_type_ids is not None:\n",
    "                        context_mask = (token_type_ids[i] == 1).cpu().numpy()\n",
    "                    else:\n",
    "                        # fallback heuristic: second half\n",
    "                        seq_len = len(s_logits)\n",
    "                        context_mask = np.zeros(seq_len, dtype=bool)\n",
    "                        context_mask[seq_len//2:] = True\n",
    "\n",
    "                    candidate_starts = np.argsort(s_logits)[-start_top_k:][::-1]\n",
    "                    candidate_ends = np.argsort(e_logits)[-end_top_k:][::-1]\n",
    "\n",
    "                    best_span = (0, 0)\n",
    "                    best_non_null_score = -float('inf')\n",
    "                    for s in candidate_starts:\n",
    "                        if not context_mask[s]:\n",
    "                            continue\n",
    "                        for e in candidate_ends:\n",
    "                            if e < s:\n",
    "                                continue\n",
    "                            length = e - s + 1\n",
    "                            if length > max_answer_length:\n",
    "                                continue\n",
    "                            if not context_mask[e]:\n",
    "                                continue\n",
    "                            score = s_logits[s] + e_logits[e]\n",
    "                            if score > best_non_null_score:\n",
    "                                best_non_null_score = score\n",
    "                                best_span = (s, e)\n",
    "\n",
    "                    # ‚úÖ FIXED: Use actual CLS index instead of hardcoded position 0\n",
    "                    null_score = s_logits[cls_idx] + e_logits[cls_idx]\n",
    "                    predict_empty = (null_score - best_non_null_score) > no_answer_threshold\n",
    "\n",
    "                    pred_text = \"\"\n",
    "                    if not predict_empty and best_non_null_score > -float('inf'):\n",
    "                        om = offset_mapping[i]\n",
    "                        if best_span[0] < len(om) and best_span[1] < len(om):\n",
    "                            start_off = om[best_span[0]]\n",
    "                            end_off = om[best_span[1]]\n",
    "                            if start_off != (0, 0) and end_off != (0, 0):\n",
    "                                char_start = start_off[0]\n",
    "                                char_end = end_off[1]\n",
    "                                ctx = contexts[i]\n",
    "                                if 0 <= char_start < char_end <= len(ctx):\n",
    "                                    pred_text = ctx[char_start:char_end].strip()\n",
    "\n",
    "                    all_predictions.append({\n",
    "                        'example_id': ex_id,\n",
    "                        'example_index': example_index,\n",
    "                        'time_step': time_step,\n",
    "                        'prediction': pred_text,\n",
    "                        'best_start': best_span[0],\n",
    "                        'best_end': best_span[1],\n",
    "                        'best_non_null_score': float(best_non_null_score),\n",
    "                        'null_score': float(null_score),\n",
    "                        'confidence': float(best_non_null_score - null_score),\n",
    "                        'predicted_empty': bool(predict_empty),\n",
    "                        'cls_index_used': int(cls_idx)  # Debug info\n",
    "                    })\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregation & metrics utilities ready\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def aggregate_document_predictions(predictions, total_examples, choose='confidence'):\n",
    "    \"\"\"Aggregate per-segment predictions into one per document.\n",
    "\n",
    "    Args:\n",
    "        predictions: list of dicts from evaluate_with_memory\n",
    "        total_examples: int number of examples\n",
    "        choose: 'confidence' | 'best_non_null_score'\n",
    "    Returns:\n",
    "        final_predictions: list[str]\n",
    "        doc_meta: list[dict] with aggregation details per example index\n",
    "    \"\"\"\n",
    "    by_doc = defaultdict(list)\n",
    "    for p in predictions:\n",
    "        if p['example_index'] >= 0:\n",
    "            by_doc[p['example_index']].append(p)\n",
    "\n",
    "    final_predictions = []\n",
    "    doc_meta = []\n",
    "    for idx in range(total_examples):\n",
    "        seg_preds = by_doc.get(idx, [])\n",
    "        if not seg_preds:\n",
    "            final_predictions.append(\"\")\n",
    "            doc_meta.append({'example_index': idx, 'segments': 0, 'chosen': None})\n",
    "            continue\n",
    "        key = 'confidence' if choose == 'confidence' else 'best_non_null_score'\n",
    "        chosen = max(seg_preds, key=lambda x: x[key])\n",
    "        final_predictions.append(chosen['prediction'])\n",
    "        doc_meta.append({\n",
    "            'example_index': idx,\n",
    "            'segments': len(seg_preds),\n",
    "            'chosen_confidence': chosen['confidence'],\n",
    "            'chosen_null_score': chosen['null_score'],\n",
    "            'predicted_empty': chosen['predicted_empty'],\n",
    "            'time_step': chosen['time_step']\n",
    "        })\n",
    "    return final_predictions, doc_meta\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, examples):\n",
    "    import string, re\n",
    "\n",
    "    def normalize_answer(s):\n",
    "        def remove_articles(text):\n",
    "            return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "        def white_space_fix(text):\n",
    "            return ' '.join(text.split())\n",
    "        def remove_punc(text):\n",
    "            exclude = set(string.punctuation)\n",
    "            return ''.join(ch for ch in text if ch not in exclude)\n",
    "        def lower(text):\n",
    "            return text.lower()\n",
    "        return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "    def compute_f1(prediction, ground_truth):\n",
    "        pred_tokens = normalize_answer(prediction).split()\n",
    "        gt_tokens = normalize_answer(ground_truth).split()\n",
    "        if len(pred_tokens) == 0 and len(gt_tokens) == 0:\n",
    "            return 1.0\n",
    "        if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
    "            return 0.0\n",
    "        common_tokens = set(pred_tokens) & set(gt_tokens)\n",
    "        if len(common_tokens) == 0:\n",
    "            return 0.0\n",
    "        precision = len(common_tokens) / len(pred_tokens)\n",
    "        recall = len(common_tokens) / len(gt_tokens)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    exact_match = 0\n",
    "    f1_scores = []\n",
    "    has_answer_exact = 0\n",
    "    has_answer_f1 = []\n",
    "    no_answer_exact = 0\n",
    "    no_answer_f1 = []\n",
    "\n",
    "    for pred, ex in zip(predictions, examples):\n",
    "        gts = ex['answers']['text']\n",
    "        if len(gts) == 0:  # no-answer\n",
    "            is_correct = (pred == \"\")\n",
    "            exact_match += int(is_correct)\n",
    "            no_answer_exact += int(is_correct)\n",
    "            score = 1.0 if is_correct else 0.0\n",
    "            f1_scores.append(score)\n",
    "            no_answer_f1.append(score)\n",
    "        else:\n",
    "            max_f1 = 0.0\n",
    "            max_exact = 0\n",
    "            for gt in gts:\n",
    "                exact = int(normalize_answer(pred) == normalize_answer(gt))\n",
    "                f1 = compute_f1(pred, gt)\n",
    "                if f1 > max_f1:\n",
    "                    max_f1 = f1\n",
    "                if exact > max_exact:\n",
    "                    max_exact = exact\n",
    "            exact_match += max_exact\n",
    "            has_answer_exact += max_exact\n",
    "            has_answer_f1.append(max_f1)\n",
    "            f1_scores.append(max_f1)\n",
    "\n",
    "    total = len(examples)\n",
    "    has_ans_count = sum(1 for ex in examples if len(ex['answers']['text']) > 0)\n",
    "    no_ans_count = total - has_ans_count\n",
    "\n",
    "    return {\n",
    "        'f1': float(np.mean(f1_scores) * 100),\n",
    "        'exact_match': exact_match / total * 100,\n",
    "        'has_answer_f1': float(np.mean(has_answer_f1) * 100) if has_answer_f1 else 0.0,\n",
    "        'has_answer_exact': has_answer_exact / has_ans_count * 100 if has_ans_count else 0.0,\n",
    "        'no_answer_f1': float(np.mean(no_answer_f1) * 100) if no_answer_f1 else 0.0,\n",
    "        'no_answer_exact': no_answer_exact / no_ans_count * 100 if no_ans_count else 0.0,\n",
    "        'total_examples': total,\n",
    "        'has_answer_count': has_ans_count,\n",
    "        'no_answer_count': no_ans_count\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Aggregation & metrics utilities ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory-Aware Evaluation Functions\n",
    "\n",
    "Implement evaluation with proper time-step-major batching and memory state propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating evaluation dataset for 100 examples using proper pipeline...\n",
      "Processing and caching squad_v2 validation...\n",
      "‚úì Processed 107 features\n",
      "Creating dataset from cache...\n",
      "[create_dataset_from_cache] Checking cache for 'squad_v2_mem32_v1' (validation) in ../.cache ...\n",
      "[create_dataset_from_cache] Cache hit: 1 chunk(s) detected. Loading ...\n",
      "[create_dataset_from_cache] Reconstructed dataset with 107 features across 100 documents (cache).\n",
      "‚úì Dataset created: 107 features\n",
      "Creating dataloader...\n",
      "‚úì DataLoader created: 13 batches\n",
      "‚úÖ Evaluation pipeline created:\n",
      "  Dataset features: 107\n",
      "  Documents: 100\n",
      "  DataLoader batches: 13\n",
      "  Memory tokens in tokenizer: 32\n",
      "\n",
      "üìã Document structure (first 3 documents):\n",
      "  doc_0: 1 segments at indices [0]\n",
      "  doc_1: 1 segments at indices [1]\n",
      "  doc_2: 1 segments at indices [2]\n",
      "[create_dataset_from_cache] Reconstructed dataset with 107 features across 100 documents (cache).\n",
      "‚úì Dataset created: 107 features\n",
      "Creating dataloader...\n",
      "‚úì DataLoader created: 13 batches\n",
      "‚úÖ Evaluation pipeline created:\n",
      "  Dataset features: 107\n",
      "  Documents: 100\n",
      "  DataLoader batches: 13\n",
      "  Memory tokens in tokenizer: 32\n",
      "\n",
      "üìã Document structure (first 3 documents):\n",
      "  doc_0: 1 segments at indices [0]\n",
      "  doc_1: 1 segments at indices [1]\n",
      "  doc_2: 1 segments at indices [2]\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation setup with a small subset first\n",
    "test_size = 100  # Start with 100 examples for testing\n",
    "\n",
    "if model is not None and tokenizer is not None:\n",
    "    print(f\"üìä Creating evaluation dataset for {test_size} examples using proper pipeline...\")\n",
    "    \n",
    "    # Use the proper data pipeline from src.data\n",
    "    eval_dataset, eval_dataloader = create_evaluation_dataloader(\n",
    "        dataset_name=\"squad_v2\",\n",
    "        split=\"validation\",\n",
    "        tokenizer=tokenizer,  # Include memory tokens\n",
    "        max_seq_length=config_data.get('max_seq_length', 384),\n",
    "        doc_stride=config_data.get('doc_stride', 64),\n",
    "        batch_size=8,\n",
    "        max_examples=test_size,\n",
    "        max_n_segs=config_data.get('max_n_segs', None),\n",
    "        cache_dir=\"../.cache\",\n",
    "        use_time_step_major=True,  # Enable time-step-major batching\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Evaluation pipeline created:\")\n",
    "    print(f\"  Dataset features: {len(eval_dataset)}\")\n",
    "    print(f\"  Documents: {len(eval_dataset.get_all_documents())}\")\n",
    "    print(f\"  DataLoader batches: {len(eval_dataloader)}\")\n",
    "    print(f\"  Memory tokens in tokenizer: {len(tokenizer) - 32000}\")\n",
    "    \n",
    "    # Show document structure for first few documents\n",
    "    print(f\"\\nüìã Document structure (first 3 documents):\")\n",
    "    for doc_id in eval_dataset.get_all_documents()[:3]:\n",
    "        segments = eval_dataset.get_document_segments(doc_id)\n",
    "        print(f\"  {doc_id}: {len(segments)} segments at indices {segments}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot create evaluation pipeline - model or tokenizer not loaded\")\n",
    "    eval_dataset = None\n",
    "    eval_dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Running evaluation subset with time-step-major batching & memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]/Users/tupa7/private/paper-revise/notebooks/../src/data.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[key] = torch.tensor(feature[key])\n",
      "/Users/tupa7/private/paper-revise/notebooks/../src/data.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[key] = torch.tensor(feature[key])\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:24<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collected 107 segment-level predictions\n",
      "‚úÖ Aggregated to 100 document predictions\n",
      "\n",
      "üìã Example predictions (first 5):\n",
      "\n",
      "--- Example 1 ---\n",
      "Question: In what country is Normandy located?...\n",
      "Prediction: 'France'\n",
      "Ground truth: ['France', 'France', 'France', 'France']\n",
      "Has answer: True\n",
      "\n",
      "--- Example 2 ---\n",
      "Question: When were the Normans in Normandy?...\n",
      "Prediction: '10th and 11th centuries'\n",
      "Ground truth: ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries']\n",
      "Has answer: True\n",
      "\n",
      "--- Example 3 ---\n",
      "Question: From which countries did the Norse originate?...\n",
      "Prediction: 'Denmark, Iceland and Norway'\n",
      "Ground truth: ['Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway']\n",
      "Has answer: True\n",
      "\n",
      "--- Example 4 ---\n",
      "Question: Who was the Norse leader?...\n",
      "Prediction: 'Rollo'\n",
      "Ground truth: ['Rollo', 'Rollo', 'Rollo', 'Rollo']\n",
      "Has answer: True\n",
      "\n",
      "--- Example 5 ---\n",
      "Question: What century did the Normans first gain their separate identity?...\n",
      "Prediction: '10th'\n",
      "Ground truth: ['10th century', 'the first half of the 10th century', '10th', '10th']\n",
      "Has answer: True\n",
      "\n",
      "üéØ SUBSET RESULTS (100 examples):\n",
      "============================================================\n",
      "f1: 35.52%\n",
      "exact_match: 28.00%\n",
      "has_answer_f1: 78.93%\n",
      "has_answer_exact: 62.22%\n",
      "no_answer_f1: 0.00%\n",
      "no_answer_exact: 0.00%\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with memory-aware processing on test subset\n",
    "if model is not None and eval_dataloader is not None:\n",
    "    print(\"üß† Running evaluation subset with time-step-major batching & memory...\")\n",
    "\n",
    "    squad_dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
    "    test_examples = squad_dataset.select(range(EVAL_CFG.test_size))\n",
    "\n",
    "    raw_predictions = evaluate_with_memory(\n",
    "        model=model,\n",
    "        eval_dataloader=eval_dataloader,\n",
    "        eval_dataset=eval_dataset,\n",
    "        device=device,\n",
    "        no_answer_threshold=EVAL_CFG.no_answer_threshold,\n",
    "        max_answer_length=EVAL_CFG.max_answer_length,\n",
    "        start_top_k=EVAL_CFG.start_top_k,\n",
    "        end_top_k=EVAL_CFG.end_top_k,\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Collected {len(raw_predictions)} segment-level predictions\")\n",
    "\n",
    "    final_predictions, doc_meta = aggregate_document_predictions(\n",
    "        raw_predictions, EVAL_CFG.test_size, choose='confidence'\n",
    "    )\n",
    "    assert len(final_predictions) == EVAL_CFG.test_size\n",
    "\n",
    "    print(f\"‚úÖ Aggregated to {len(final_predictions)} document predictions\")\n",
    "\n",
    "    # Preview\n",
    "    print(\"\\nüìã Example predictions (first 5):\")\n",
    "    for i in range(min(5, EVAL_CFG.test_size)):\n",
    "        example = test_examples[i]\n",
    "        prediction = final_predictions[i]\n",
    "        ground_truth = example['answers']['text']\n",
    "        print(f\"\\n--- Example {i+1} ---\")\n",
    "        print(f\"Question: {example['question'][:80]}...\")\n",
    "        print(f\"Prediction: '{prediction}'\")\n",
    "        print(f\"Ground truth: {ground_truth}\")\n",
    "        print(f\"Has answer: {len(ground_truth) > 0}\")\n",
    "\n",
    "    subset_metrics = compute_metrics(final_predictions, test_examples)\n",
    "    print(f\"\\nüéØ SUBSET RESULTS ({EVAL_CFG.test_size} examples):\")\n",
    "    print('=' * 60)\n",
    "    for k in ['f1','exact_match','has_answer_f1','has_answer_exact','no_answer_f1','no_answer_exact']:\n",
    "        print(f\"{k}: {subset_metrics[k]:.2f}%\")\n",
    "    print('=' * 60)\n",
    "else:\n",
    "    print(\"‚ùå Cannot run subset evaluation - model or dataloader not available\")\n",
    "    subset_metrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Evaluation\n",
    "\n",
    "Execute the complete evaluation pipeline with memory-enabled processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Dataset Evaluation\n",
    "\n",
    "Now let's run on the complete SQuAD v2 validation set to get the final F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Full evaluation skipped (set EVAL_CFG.use_full_eval=True to enable)\n"
     ]
    }
   ],
   "source": [
    "# Full evaluation pipeline (optional)\n",
    "if model is not None and tokenizer is not None and subset_metrics is not None and EVAL_CFG.use_full_eval:\n",
    "    print(\"üìä Building full evaluation dataloader...\")\n",
    "    full_eval_dataset, full_eval_dataloader = create_evaluation_dataloader(\n",
    "        dataset_name=\"squad_v2\",\n",
    "        split=\"validation\",\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=config_data.get('max_seq_length', 384),\n",
    "        doc_stride=config_data.get('doc_stride', 64),\n",
    "        batch_size=EVAL_CFG.batch_size,\n",
    "        max_examples=None,\n",
    "        max_n_segs=config_data.get('max_n_segs', None),\n",
    "        cache_dir=\"../.cache\",\n",
    "        use_time_step_major=True,\n",
    "    )\n",
    "    print(f\"‚úÖ Full dataset features: {len(full_eval_dataset)}\")\n",
    "else:\n",
    "    full_eval_dataset = None\n",
    "    full_eval_dataloader = None\n",
    "    print(\"‚ÑπÔ∏è Full evaluation skipped (set EVAL_CFG.use_full_eval=True to enable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute full evaluation if enabled\n",
    "if full_eval_dataloader is not None:\n",
    "    print(\"üöÄ Running full validation evaluation...\")\n",
    "    full_squad_dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
    "\n",
    "    full_raw_predictions = evaluate_with_memory(\n",
    "        model=model,\n",
    "        eval_dataloader=full_eval_dataloader,\n",
    "        eval_dataset=full_eval_dataset,\n",
    "        device=device,\n",
    "        no_answer_threshold=EVAL_CFG.no_answer_threshold,\n",
    "        max_answer_length=EVAL_CFG.max_answer_length,\n",
    "        start_top_k=EVAL_CFG.start_top_k,\n",
    "        end_top_k=EVAL_CFG.end_top_k,\n",
    "    )\n",
    "    print(f\"‚úÖ Collected {len(full_raw_predictions)} segment-level predictions\")\n",
    "\n",
    "    full_final_predictions, full_doc_meta = aggregate_document_predictions(\n",
    "        full_raw_predictions, len(full_squad_dataset)\n",
    "    )\n",
    "    assert len(full_final_predictions) == len(full_squad_dataset)\n",
    "\n",
    "    final_metrics = compute_metrics(full_final_predictions, full_squad_dataset)\n",
    "\n",
    "    print(\"\\nüèÜ FULL VALIDATION RESULTS:\")\n",
    "    print('=' * 70)\n",
    "    for k in ['f1','exact_match','has_answer_f1','has_answer_exact','no_answer_f1','no_answer_exact']:\n",
    "        print(f\"{k}: {final_metrics[k]:.2f}%\")\n",
    "    print('=' * 70)\n",
    "\n",
    "    goal_achieved = final_metrics['f1'] >= 80.0\n",
    "    print(\"\\nGoal:\", '‚úÖ Achieved' if goal_achieved else 'üìà Not yet')\n",
    "else:\n",
    "    full_raw_predictions = None\n",
    "    full_final_predictions = None\n",
    "    full_doc_meta = None\n",
    "    final_metrics = None\n",
    "    goal_achieved = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation handled in previous cells. Nothing to do here.\n"
     ]
    }
   ],
   "source": [
    "# (Removed obsolete aggregation misuse) Placeholder cell kept intentionally.\n",
    "print(\"Aggregation handled in previous cells. Nothing to do here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Full metrics not computed (full eval skipped or failed)\n"
     ]
    }
   ],
   "source": [
    "# Display final metrics if available\n",
    "if final_metrics is not None:\n",
    "    print(\"\\nüèÜ FINAL (FULL) EVALUATION RESULTS:\")\n",
    "    print('=' * 60)\n",
    "    for k in ['f1','exact_match','has_answer_f1','has_answer_exact','no_answer_f1','no_answer_exact']:\n",
    "        print(f\"{k}: {final_metrics[k]:.2f}%\")\n",
    "    print('=' * 60)\n",
    "    if final_metrics['f1'] >= 80.0:\n",
    "        print(f\"‚úÖ Success: F1 {final_metrics['f1']:.2f}% >= 80% target\")\n",
    "    else:\n",
    "        print(f\"üìà F1 {final_metrics['f1']:.2f}% (target 80%)\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Full metrics not computed (full eval skipped or failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary and Analysis\n",
    "\n",
    "Analysis of results and next steps for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confidence analysis (subset or full if available)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if full_doc_meta is not None:\n",
    "    meta = full_doc_meta\n",
    "    label = 'Full'\n",
    "elif 'doc_meta' in locals():\n",
    "    meta = doc_meta\n",
    "    label = 'Subset'\n",
    "else:\n",
    "    meta = None\n",
    "\n",
    "if meta is not None:\n",
    "    confidences = [m['chosen_confidence'] for m in meta if m['chosen_confidence'] is not None]\n",
    "    empty_flags = [m['predicted_empty'] for m in meta if m['chosen_confidence'] is not None]\n",
    "    has_conf = np.array([not f for f in empty_flags], dtype=bool)\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.hist([np.array(confidences)[has_conf], np.array(confidences)[~has_conf]],\n",
    "             bins=40, label=['Pred Answer','Pred Empty'], alpha=0.7)\n",
    "    plt.axvline(0.0, color='black', linestyle='--', label='0 margin')\n",
    "    plt.title(f'{label} Confidence Distribution (best_non_null - null)')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No meta available for confidence analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved results to ../evaluation_results_memxlnet.json\n"
     ]
    }
   ],
   "source": [
    "# Save results summary\n",
    "import json, time\n",
    "\n",
    "if final_metrics is not None or subset_metrics is not None:\n",
    "    results_summary = {\n",
    "        'checkpoint_path': EVAL_CFG.checkpoint_path,\n",
    "        'subset_metrics': subset_metrics,\n",
    "        'full_metrics': final_metrics,\n",
    "        'used_full_eval': EVAL_CFG.use_full_eval,\n",
    "        'config_overrides': {\n",
    "            'no_answer_threshold': EVAL_CFG.no_answer_threshold,\n",
    "            'start_top_k': EVAL_CFG.start_top_k,\n",
    "            'end_top_k': EVAL_CFG.end_top_k,\n",
    "            'max_answer_length': EVAL_CFG.max_answer_length\n",
    "        },\n",
    "        'timestamp': time.time(),\n",
    "        'doc_meta_sample': (full_doc_meta[:10] if full_doc_meta else doc_meta[:10] if 'doc_meta' in locals() else [])\n",
    "    }\n",
    "    out_path = '../evaluation_results_memxlnet.json'\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    print(f\"üíæ Saved results to {out_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No metrics available to save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
